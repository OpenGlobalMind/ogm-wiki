<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="fs_path" content="/Projects/Jerry's Nuggets/GenAI Trust Issues.md">
    
    <title>GenAI Trust Issues - OGM Wiki</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/ogm-wiki/markpub_static/css/style.css">
    <link rel="stylesheet" href="/ogm-wiki/markpub_static/css/custom.css">
    <link rel="stylesheet" href="https://unpkg.com/bluesky-comments@0.12.0/dist/bluesky-comments.css">
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js"></script>
    <script src="/ogm-wiki/lunr-index-1769294205.47985.js"></script>
    <script>var index = lunr.Index.load(lunr_index)</script>
    
    
    <script src="/ogm-wiki/lunr-posts-1769294205.47985.js"></script>
    <script> function randomPageLink() { return "/ogm-wiki"+lunr_posts[Math.floor(Math.random() * lunr_posts.length)].link; } </script>
    
  </head>
<body>
  <div id="header">
    <span id="hamburger-btn"
    class="hidden">&#9776;</span><a class="button is-light" id="header-link" href="/ogm-wiki/index.html">OGM Wiki</a>
  </div>

  <div class="container" id="flex-container">
    <div id="side-column">
      <div>
        <button id="hide-btn">Hide</button>
        <button id="move-btn" class="hidden">Move to Sidebar</button>
      </div>
      <p>This site is a <a class="wikilink" href="/ogm-wiki/Admin_and_Help/System_Pages/Work_In_Progress.html">Work In Progress</a></p>
<h3>Site Navigation</h3>
<div class="navlinks">
<ul>
<li><a class="wikilink" href="/ogm-wiki/README.html">HOME</a></li>
<li><a href="/ogm-wiki/search.html">SEARCH</a></li>
<li><a href="/ogm-wiki/all-pages.html">ALL PAGES</a></li>
<li><a href="/ogm-wiki/recent-pages.html">RECENT CHANGES</a></li>
</ul>
</div>
<div class="navlinks">
  <button onclick="location.href=`${randomPageLink()}`">
    RANDOM PAGE
  </button>
</div>
<p><a class="wikilink" href="/ogm-wiki/Projects/NeoBooks_In_Progress.html">NeoBooks In Progress</a></p>
<p><a class="wikilink" href="/ogm-wiki/NeoBooks_Ops/Creating_a_NeoBook_(start_here).html">Creating a NeoBook (start here)</a></p>
<p><a class="wikilink" href="/ogm-wiki/Admin_and_Help/Admin_and_Help.html">Admin and Help</a></p>

    </div>

    <div id="main-column">
      
      <div> <!-- edit this page button -->
	<p style="float:right; margin:.5em .5em
	.5em"><a target="_blank" href="https://github.com/openglobalmind/ogm-wiki/edit/main/Projects/Jerry's Nuggets/GenAI Trust Issues.md"
	class="edit-this-page-button">Edit on GitHub</a></p>
	<br clear="all">
      </div> <!-- edit this page button -->
      
      <h1>GenAI's Trust Issues</h1>
<p>(draft)</p>
<h3>Q: Do you think most people are stuck feeling like navigating all this tech disruption is impossible. And if so, what’s the first mindset shift that could change that?</h3>
<p>I'm an optimist that GenAI nets quite positive in the longer run. But everything depends on how you approach it. Two stops and a start.</p>
<p><strong>Stop thinking this is all on you</strong>. There are too many issues and possibilities, with too many implications. Find your way to group mind, collective intelligence: <a href="https://www.youtube.com/watch?v=cA8xObrgD7s">scenius</a>. Let go of the need to have all the answers. Instead, share that load with others on the same quest, and create conditions that will encourage such magic to emerge.</p>
<p>By the way, it's not just your mind plus all your staff's: there's a new hybrid intelligence in the room, too. What does intelligence look like when all three are humming in harmony? I find that really exciting, though I can see that it might be really scary, too. So take your time.</p>
<p><strong>Stop thinking that GenAI is either a flesh-eating bacterium that will end humanity, or the most idealized scientist who will do your bidding and fix humanity</strong>. There's a bit of both, but GenAI is more like a tireless Australian shepherd that can talk and has 50 PhDs.</p>
<p><strong>Start thinking how to leap over the many trust hurdles present. Together.</strong> So you can get the most out of its potential to help.</p>
<p>Self-leadership. People are being more open. Leaders need to be brave. Courage/Brené Brown. Less foolhardy, more wholehearted.</p>
<p>Do we need to have keynotes just around the vulnerability? the human piece? We defend what worked, don't let go easily. We're so adaptable and so loyal to our beliefs. We need a Wayze for AI strategy! Ethan Mollick</p>
<p>Values.
Two phases: 1. what they value, how they want things to go. some are surprised. 2. one speaker hired, decisionmaker comes in, good discussion w speaker. we define leadership differently. people who give good Zoom :)  several times in my career that definitions really mattered. why I love working w Brian.</p>
<p>Reshaping the keynote industry. Using my Brain. Facilitation. Continuity.
what's best way to deliver?</p>
<h3>Q: When it comes to achieving audacious goals, isn’t TRUST at the core?</h3>
<p>You can't get something done across an organization if half the staff are afraid of the change. Each organization has its own culture, sometimes varying from dept to dept, but any worker who has been paying attention to the world of business the last few decades has good reasons to be worried.</p>
<p>You've heard of "Shadow AI"? That's when workers are using AI to get their work done, but in secret.</p>
<p>But <strong>the elephant in the room</strong> is whether your own job will be wiped out by AI — likely without warning. There's a kind of Sword of Damocles hanging over everyone these days. The thread could snap and it could drop on anyone, at any time. But it doesn't have to be there. What you really want is everyone collaborating to implement GenAI wisely, rearranging all the work (and therefore jobs) along the way. It's a kind of fluidity most organizations don't have, but it presents enormous opportunities. But workers need to feel confident that they will get a square deal, a fair shake — whatever that means in your context.</p>
<p>GenAI eats tasks, not jobs.</p>
<h3>Q: Around this idea of Augment or Replace – Will AI help us become ‘super humans’ — or will it replace us? How do you see trust shaping which of those futures we end up living?</h3>
<p>The</p>
<p>First, this is all about how you approach it. Your intentions are telegraphed through your actions.</p>
<h3>Trust issues</h3>
<p>The advent of Generative AI raises a series of important questions related to trust, including:</p>
<ul>
<li>Can I trust GenAI's answers? (hallucinations, black box problem)</li>
<li>Can our clients trust GenAI's answers? (our policies, choices and systems design)</li>
<li>Is GenAI stealing all our ideas? (for training, while interacting)</li>
<li>What about my personal information?</li>
<li>Will GenAI take my job? (the social contract)</li>
<li>If it does, what on earth should I aim for next?</li>
<li>Should I tell anyone I'm using GenAI?</li>
<li>Is everyone cheating?</li>
<li>How can I tell something was generated by AI? (norms)</li>
<li>Can I trust communications I see? (deepfakes)</li>
<li>Can I trust myself to do the right thing with GenAI? (new forms of leadership)</li>
</ul>
<p>Huge trust questions to set aside for the moment:</p>
<ul>
<li>Do these new intelligences have our best interests at heart? Can we trust them?</li>
<li>If I use them intensely, will I lose my humanity? Skills? Memory?</li>
<li>AGI: will these new intelligences obsolete humans?</li>
</ul>
<h3>On constraints:</h3>
<p>I'm always amazed at how nearsighted, forgetful and adaptable we are, and how loyal we are to what we believe (until that changes).</p>
<p>Answers:</p>
<ul>
<li><a class="wikilink" href="/ogm-wiki/Projects/Jerry's_Nuggets/The_Elephant_in_the_GenAI_Room.html">The Elephant in the GenAI Room</a></li>
<li><a class="wikilink" href="/ogm-wiki/Projects/Jerry's_Nuggets/GenAI_Is_Like_a_Flesh-Eating_Bacterium.html">GenAI Is Like a Flesh-Eating Bacterium</a></li>
</ul>
<p>The Red Wheelbarrow</p>
<blockquote>
<p>so much depends<br />
upon</p>
<p>a red wheel<br />
barrow</p>
<p>glazed with rain<br />
water</p>
<p>beside the white<br />
chickens.</p>
</blockquote>

      
      <hr>
      <div>
	<h4>Pages that link to this page</h4>
	<ul>
	  
	  <li><a href="/ogm-wiki/Projects/Jerry's_Nuggets/RC_Posts.html">RC Posts</a>
	  
	  <li><a href="/ogm-wiki/Projects/Jerry's_Nuggets/Trust_Unlocks_Innovation.html">Trust Unlocks Innovation</a>
	  
	  <li><a href="/ogm-wiki/Projects/Jerry's_Nuggets/Jerry's_Presentation_Nuggets.html">Jerry's Presentation Nuggets</a>
	  
	  <li><a href="/ogm-wiki/Projects/Jerry's_Nuggets/The_Queue.html">The Queue</a>
	  
	</ul>
      </div>
      
    </div>
  </div>
  <script src="/ogm-wiki/markpub_static/js/script.js"></script>
  
  <footer class="footer">
  <div class="content has-text-centered">
    
    <div><strong>OGM Wiki</strong> by the Open Global Mind community.</div>
    
    
    <div>Central repository at <a href="https://github.com/openglobalmind/ogm-wiki">GitHub/openglobalmind/ogm-wiki</a>.</div>
    
    
    <div>Licensed under <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</div>
    
    <div><em>Site last updated on Saturday, January 24, 2026 at 22:36 UTC.</em></div>
  </div>
</footer>
</body>
</html>