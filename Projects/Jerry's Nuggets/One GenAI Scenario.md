# One GenAI Scenario 
(draft) 
*How this thing might play out.* 

Here's one narrative of how the next decade or two might play out, given the current state of GenAI and the promises (and threats) that it holds. 

Generative AI progress continues (we're not at a plateau).
- Including sharp gains in efficiency, like DeepSeek and Gemma 3.
- (The apocalyptic trends of GenAI eating all resources don't account for these.)
Bootstrapping starts. GenAI is able to improve itself at a dramatic pace.
GenAI is already better than humans in a lot of verticals.
We and they learn to bridge domains and to arbitrate between different models, depending on which ones are best at solving the problems.
This starts to smell like AGI. (depending on your definition of AGI.)

Meanwhile...
Capitalism is doing its thing.
- Many people are losing their jobs to automation.
- Most of the others are afraid that is going to happen to them.
- The current system is particularly cruel to people who have lost their jobs.
- The Trump administration is busy tearing down the safety nets. 
- Many people who get to keep their jobs find their workload has multiplied incredibly.
This pressure and uncertainty explodes in the streets.

Meanwhile...
Nobody figures out a good way to regulate or constrain GenAI.
Bad actors take open-source GenAI models and go crazy.
But it's an arms race: Good actors manage to neutralize most of these efforts, but not all. 

To overgeneralize, from here there are two paths:
- The system spirals downward out of control into chaos.
- Or we learn to renegotiate the social contract, making room for people who are unemployed, rethinking jobs, and rebuilding trust between workers and managers.

The first path is really, really ugly because our current flavor of capitalism is very unforgiving to people who have lost their jobs.
- It's especially hard for somebody who has lost their job to find a new one because they didn't lose their job, they lost their occupation: What they trained for is likely gone for good, replaced by GenAI. They have been unceremoniously chucked to the bottom of the labor pool. 
- It's extremely dicey what thing they should train for next because it might be gone before they actually get trained up. The speed with which tasks are being automated is quicker than the time it takes to qualify a human on those tasks. 
- All of this sews intense anxiety and discontent. 

The second path is preferable, difficult, and unlikely. 

There are actually many second paths, but I'm going to describe just one. One that depends entirely on rebuilding the trust that we have managed to break and lose in the last few decades.

I'm convinced enough that trust is a key lever here that I did a keynote speech in 2020 titled "[Trust Is the (Only) Way Forward](https://youtu.be/gf3vp0Wquz8)" and then I did a speech [two years later](https://www.youtube.com/watch?v=N47GRiYZ0p8) at the same event to explain my reasoning. In that second talk, I dug into the sources of my ideas, the way that I had sifted those ideas together into a thesis, and how it all might fit together to help us humans. 

This is the part where a miracle has to happen. I would love to see people in groups everywhere using [[Design from Trust]] to improve their neighborhoods, their communities, their watersheds, and their governance systems. The minor stumbling block is that nobody knows quite what that is. 

Our default outcome, the one that shows up if we don't change things pretty dramatically, is bleak.

## Wild cards 

Several things that would really throw a wrench in the works are not hard to imagine. For example:
- The boom in Agentic AI means these new AIs will have their hands on the steering wheel. Our attempts to put the brakes on will not always succeed.
- Bad actors around the world will be actively removing the brakes.
- GenAI could get ahead of us. Whether you call that superintelligence or AGI, it's not hard to imagine systems that can respond quicker, know more, and really cause havoc. 
- It doesn't take Martha Wells, Stanislaw Lem, or Cory Doctorow to paint these futures. 
- The blurring of the line between fiction and reality, or what humans do and what machines do, could catalyze a break at a civilizational scale. 

## Current stance 

I'm a cynical optimist. I believe people are actually smarter and more trustworthy than we think they are and given options to make humanity better might actually participate and do that, particularly when there are looming threats nearby.