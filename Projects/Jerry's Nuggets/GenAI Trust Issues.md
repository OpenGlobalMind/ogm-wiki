# GenAI's Trust Issues
 (draft) 


Our appetite for AI. Watching it grow since late 1980s. Double-edged sword. Story about noir cyberpunk series. Clients having trouble thinking about it. Plates were full before it showed up. So played it safe, went slowly. 

What if AI leapfrogs us to a deeper place? 
### Q: Do you think most people are stuck feeling like navigating all this tech disruption is impossible. And if so, what’s the first mindset shift that could change that? 

I'm an optimist that GenAI nets quite positive in the longer run. But everything depends on how you approach it. Two stops and a start. 

**Stop thinking this is all on you**. There are too many issues and possibilities, with too many implications. Find your way to group mind, collective intelligence, scenius. And it's not just your mind plus all your staff's: there's a new hybrid intelligence in the room, too. What does intelligence look like when all three are humming in harmony? I find that really exciting, though I can see that it might be really scary, too. So take your time. 

**Stop thinking that GenAI is either a flesh-eating bacterium that will end humanity, or the most idealized scientist who will do your bidding and fix humanity**. There's a bit of both, but GenAI is more like a tireless Australian shepherd that can talk and has 50 PhDs. 

**Start thinking how to leap over the many trust hurdles present. Together.** So you can get the most out of its potential to help. 

Self-leadership. People are being more open. Leaders need to be brave. Courage/Brene Brown. 

Do we need to have keynotes just around the vulnerability? the human piece? We defend what worked, don't let go easily. We're so adaptable and so loyal to our beliefs. We need a Wayze for AI strategy! Ethan Mollick 

Values. 
Two phases: 1. what they value, how they want things to go. some are surprised. 2. one speaker hired, decisionmaker comes in, good discussion w speaker. we define leadership differently. people who give good Zoom :)  several times in my career that definitions really mattered. why I love working w Brian. 

Reshaping the keynote industry. Using my Brain. Facilitation. Continuity. 
what's best way to deliver? 

### Q: When it comes to achieving audacious goals, isn’t TRUST at the core? 

You can't get something done across an organization if half the staff are afraid of the change. Each organization has its own culture, sometimes varying from dept to dept, but any worker who has been paying attention to the world of business the last few decades has good reasons to be worried. 

You've heard of "Shadow AI"? That's when workers are using AI to get their work done, but in secret. 

But **the elephant in the room** is whether your own job will be wiped out by AI — likely without warning. There's a kind of Sword of Damocles hanging over everyone these days. The thread could snap and it could drop on anyone, at any time. But it doesn't have to be there. What you really want is everyone collaborating to implement GenAI wisely, rearranging all the work (and therefore jobs) along the way. It's a kind of fluidity most organizations don't have, but it presents enormous opportunities. But workers need to feel confident that they will get a square deal, a fair shake — whatever that means in your context. 

GenAI eats tasks, not jobs. 

### Q: How much does every individual trust themselves on this journey. I feel that we are made for this moment. We are innately creative, adaptive, and capable of leading with curiosity instead of fear. How do you think that individual courage can scale into collective transformation? 

Yes! 

### Q: One person shared: “Billions are being invested in AI technology — but far less in understanding humanity.” Jerry, from your perspective, how can leaders balance the trust they place in AI with an equally strong investment in understanding the humans it’s meant to serve? 

The 

### Q: Around this idea of Augment or Replace – Will AI help us become ‘super humans’ — or will it replace us? How do you see trust shaping which of those futures we end up living?

The 

### Q: From speaker David Allison, a Human Values Research Pioneer. David says: “Once you can pinpoint the precise shared values that matter to people—the values most affected by AI—you can craft engagement strategies that align with what they already care about.” How have you seen shared values help build trust and adoption in practice?


First, this is all about how you approach it. Your intentions are telegraphed through your actions. 

### Trust issues 

The advent of Generative AI raises a series of important questions related to trust, including: 

- Can I trust GenAI's answers? (hallucinations, black box problem) 
- Can our clients trust GenAI's answers? (our policies, choices and systems design) 
- Is GenAI stealing all our ideas? (for training, while interacting)
- What about my personal information? 
- Will GenAI take my job? (the social contract)
- If it does, what on earth should I aim for next? 
- Should I tell anyone I'm using GenAI? 
- Is everyone cheating? 
- How can I tell something was generated by AI? (norms)
- Can I trust communications I see? (deepfakes)
- Can I trust myself to do the right thing with GenAI? (new forms of leadership)

Huge trust questions to set aside for the moment: 

 - Do these new intelligences have our best interests at heart? Can we trust them? 
 - If I use them intensely, will I lose my humanity? Skills? Memory? 
 - AGI: will these new intelligences obsolete humans? 

### On constraints: 

I'm always amazed at how nearsighted, forgetful and adaptable we are, and how loyal we are to what we believe (until that changes). 

Answers: 

- [[The Elephant in the GenAI Room]] 
- [[GenAI Is Like a Flesh-Eating Bacterium]] 


The Red Wheelbarrow

> so much depends  
> upon
> 
> a red wheel  
> barrow
> 
> glazed with rain  
> water
> 
> beside the white  
> chickens.

