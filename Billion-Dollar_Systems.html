<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="fs_path" content="/Billion-Dollar Systems.md">
    
    <title>Billion-Dollar Systems - OGM Wiki</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/ogm-wiki/markpub_static/css/style.css">
    <link rel="stylesheet" href="/ogm-wiki/markpub_static/css/custom.css">
    <link rel="stylesheet" href="https://unpkg.com/bluesky-comments@0.12.0/dist/bluesky-comments.css">
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js"></script>
    <script src="/ogm-wiki/lunr-index-1769619520.3695896.js"></script>
    <script>var index = lunr.Index.load(lunr_index)</script>
    
    
    <script src="/ogm-wiki/lunr-posts-1769619520.3695896.js"></script>
    <script> function randomPageLink() { return "/ogm-wiki"+lunr_posts[Math.floor(Math.random() * lunr_posts.length)].link; } </script>
    
  </head>
<body>
  <div id="header">
    <span id="hamburger-btn"
    class="hidden">&#9776;</span><a class="button is-light" id="header-link" href="/ogm-wiki/index.html">OGM Wiki</a>
  </div>

  <div class="container" id="flex-container">
    <div id="side-column">
      <div>
        <button id="hide-btn">Hide</button>
        <button id="move-btn" class="hidden">Move to Sidebar</button>
      </div>
      <p>This site is a <a class="wikilink" href="/ogm-wiki/Admin_and_Help/System_Pages/Work_In_Progress.html">Work In Progress</a></p>
<h3>Site Navigation</h3>
<div class="navlinks">
<ul>
<li><a class="wikilink" href="/ogm-wiki/README.html">HOME</a></li>
<li><a href="/ogm-wiki/search.html">SEARCH</a></li>
<li><a href="/ogm-wiki/all-pages.html">ALL PAGES</a></li>
<li><a href="/ogm-wiki/recent-pages.html">RECENT CHANGES</a></li>
</ul>
</div>
<div class="navlinks">
  <button onclick="location.href=`${randomPageLink()}`">
    RANDOM PAGE
  </button>
</div>
<p><a class="wikilink" href="/ogm-wiki/Projects/NeoBooks_In_Progress.html">NeoBooks In Progress</a></p>
<p><a class="wikilink" href="/ogm-wiki/NeoBooks_Ops/Creating_a_NeoBook_(start_here).html">Creating a NeoBook (start here)</a></p>
<p><a class="wikilink" href="/ogm-wiki/Admin_and_Help/Admin_and_Help.html">Admin and Help</a></p>

    </div>

    <div id="main-column">
      
      <div> <!-- edit this page button -->
	<p style="float:right; margin:.5em .5em
	.5em"><a target="_blank" href="https://github.com/openglobalmind/ogm-wiki/edit/main/Billion-Dollar Systems.md"
	class="edit-this-page-button">Edit on GitHub</a></p>
	<br clear="all">
      </div> <!-- edit this page button -->
      
      <h1>What Now?</h1>
<h1>We've Been Building Billion-Dollar Systems That Make the Problem Worse</h1>
<h2>An outline for your next post</h2>
<hr />
<h2>Opening Hook</h2>
<p><strong>Subtitle:</strong> <em>How mistrust-by-design creates the crises it claims to solve</em></p>
<p>Start with a specific, visceral example of a system failing expensively:</p>
<ul>
<li>TSA security theater: $8+ billion annually, negligible security improvement, massive inconvenience</li>
<li>The 95% failure rate in their own tests</li>
<li>Meanwhile, the actual solution (reinforced cockpit doors) cost a fraction and actually worked</li>
<li>This isn't incompetence—it's what happens when you design from mistrust</li>
</ul>
<p><strong>The pattern:</strong> We keep building expensive control systems that:</p>
<ol>
<li>Don't solve the original problem</li>
<li>Create new problems</li>
<li>Demand even more expensive "solutions"</li>
<li>Leave everyone worse off</li>
</ol>
<p>This is the doom loop of mistrust-by-design.</p>
<hr />
<h2>Part 1: The Vicious Cycle</h2>
<p><strong>How mistrust creates the problems it tries to prevent</strong></p>
<h3>Education's Spiral</h3>
<ul>
<li>Started with: concern that some students weren't learning</li>
<li>Response: standardized testing, accountability metrics, teach-to-test curricula</li>
<li>Cost: billions in testing infrastructure, lost classroom time, narrowed curriculum</li>
<li>Result: students hate learning more, teachers quit in record numbers, creativity plummets</li>
<li>Next response: more testing, more accountability, more controls</li>
<li>The actual problem (engagement, meaning, agency) gets worse with each "solution"</li>
</ul>
<h3>The Surveillance Workplace</h3>
<ul>
<li>Started with: worry about productivity and time theft</li>
<li>Response: monitoring software, keystroke logging, activity tracking, bathroom break metrics</li>
<li>Cost: billions in surveillance tech, massive management overhead, legal risks</li>
<li>Result: employee engagement hits all-time lows, quiet quitting, actual productivity drops</li>
<li>Next response: AI surveillance, predictive analytics, even tighter controls</li>
<li>The actual problem (trust, autonomy, meaning) deteriorates further</li>
</ul>
<h3>Healthcare's Permission Labyrinth</h3>
<ul>
<li>Started with: legitimate safety concerns and liability fears</li>
<li>Response: prior authorizations, step therapy, formulary restrictions, documentation requirements</li>
<li>Cost: physicians spend 2+ hours on paperwork per hour of patient care, billions in administrative overhead</li>
<li>Result: doctors burned out, patients getting sicker waiting for approvals, crucial time lost</li>
<li>Next response: more gatekeeping, more documentation, more controls</li>
<li>The actual problem (patient care) becomes almost incidental</li>
</ul>
<p><strong>The pattern across all three:</strong></p>
<ul>
<li>Control costs more than trust</li>
<li>Control doesn't solve the underlying problem</li>
<li>Control often makes the underlying problem worse</li>
<li>So we add more control</li>
</ul>
<hr />
<h2>Part 2: The Hidden Costs Nobody Counts</h2>
<p><strong>What we lose when we design from mistrust</strong></p>
<h3>The Innovation Tax</h3>
<ul>
<li>Every permission requirement is an innovation killed</li>
<li>Case study: Compare pharmaceutical innovation (heavily regulated, slow, expensive) to software innovation (relatively open, fast, cheap)</li>
<li>Not arguing against all pharma regulation, but noting the cost</li>
<li>How many cures don't exist because the system assumes bad actors?</li>
<li>The genius trapped behind "not your job" boundaries</li>
</ul>
<h3>The Circumvention Economy</h3>
<ul>
<li>People spend enormous energy gaming control systems</li>
<li>Students learning to cheat rather than learning the material</li>
<li>Employees appearing busy rather than being productive</li>
<li>Patients learning to "speak insurance" rather than describing symptoms</li>
<li>Massive waste of human creativity applied to defeating systems instead of improving them</li>
</ul>
<h3>The Disconnection Cost</h3>
<ul>
<li>When systems treat people as potential criminals, people disconnect</li>
<li>"Learned helplessness" becomes rational response to learned powerlessness</li>
<li>The civic engagement we desperately need dies under surveillance</li>
<li>Case study: Compare Wikipedia editor engagement vs. traditional encyclopedia contributors</li>
<li>Trust creates belonging; mistrust creates alienation</li>
</ul>
<h3>The Brittle System Problem</h3>
<ul>
<li>Heavily controlled systems can't adapt</li>
<li>They break catastrophically instead of bending</li>
<li>Case study: Blockbuster's inability to adapt vs. Netflix's emergence</li>
<li>Case study: Encyclopedia Britannica vs. Wikipedia's resilience</li>
<li>Centralized control = single points of failure</li>
<li>Distributed trust = antifragile systems</li>
</ul>
<hr />
<h2>Part 3: Why We Keep Doing This</h2>
<p><strong>The forces that perpetuate mistrust-by-design</strong></p>
<h3>The Liability Trap</h3>
<ul>
<li>One lawsuit creates policy for thousands</li>
<li>We design for the worst case, punishing everyone for one person's action</li>
<li>The legal system rewards defensive design over effective design</li>
<li>Insurance requirements that mandate mistrust</li>
</ul>
<h3>The Professionalization Racket</h3>
<ul>
<li>Expert gatekeeping protects incumbents</li>
<li>Credentials as barrier to entry, not guarantee of quality</li>
<li>Case study: How many great teachers can't teach because they lack the "right" degree?</li>
<li>Case study: Occupational licensing that protects profits, not public</li>
</ul>
<h3>The Quantification Delusion</h3>
<ul>
<li>"If you can't measure it, you can't manage it" leads to measuring the wrong things</li>
<li>What's easily measured (test scores, keystrokes, time-on-task) isn't what matters</li>
<li>What matters (learning, innovation, care) becomes secondary</li>
<li>Goodhart's Law on steroids: when a measure becomes a target, it ceases to be a good measure</li>
</ul>
<h3>The Security Theater Business Model</h3>
<ul>
<li>Entire industries profit from fear and mistrust</li>
<li>Surveillance capitalism needs us to mistrust each other</li>
<li>The consulting complex that sells "solutions" to trust problems</li>
<li>Political incentives that reward being "tough" on X</li>
</ul>
<h3>The Ratchet Effect</h3>
<ul>
<li>Controls almost never get removed</li>
<li>Each crisis adds a layer</li>
<li>We rarely ask: "Did that control actually work?"</li>
<li>We just add more when problems persist</li>
<li>Organizations develop scar tissue that never heals</li>
</ul>
<hr />
<h2>Part 4: What the Billion Dollars Could Buy Instead</h2>
<p><strong>The opportunity cost of mistrust</strong></p>
<h3>Real Examples of Trust-Based Alternatives</h3>
<p><strong>Morning Star (self-management)</strong></p>
<ul>
<li>No managers, no job titles, workers negotiate commitments</li>
<li>Tomato processing company, not a tech startup</li>
<li>More profitable than competitors, lower turnover</li>
<li>What they DON'T spend money on: management hierarchy, HR bureaucracy, performance reviews</li>
<li>What they DO spend money on: training, equipment, employee development</li>
</ul>
<p><strong>Buurtzorg (neighborhood nursing)</strong></p>
<ul>
<li>Netherlands nursing organization, eliminated management layers</li>
<li>Teams of 10-12 nurses self-organize patient care</li>
<li>50% less administrative overhead than traditional nursing</li>
<li>Better patient outcomes, higher nurse satisfaction, lower costs</li>
<li>What they saved: billions in management costs</li>
<li>What they gained: better care, happier nurses</li>
</ul>
<p><strong>Semco (radical workplace democracy)</strong></p>
<ul>
<li>Employees set own salaries, choose managers, define work hours</li>
<li>Revenue grew from $4M to $212M with this model</li>
<li>Skeptics said it would fail immediately</li>
<li>It's been running for 40+ years</li>
<li>What they saved: oversight bureaucracy, turnover costs, engagement consultants</li>
<li>What they gained: innovation, loyalty, profitability</li>
</ul>
<h3>The Math Nobody Does</h3>
<p>If we took just the surveillance and control budgets from:</p>
<ul>
<li>Educational testing and accountability systems</li>
<li>Workplace monitoring and management</li>
<li>Healthcare prior authorization and documentation</li>
<li>TSA and security theater</li>
<li>Professional licensing boards</li>
<li>And redirected it to trust-based alternatives...</li>
</ul>
<p>What could we build?</p>
<ul>
<li>Teacher-directed schools with real resources</li>
<li>Worker-owned cooperatives</li>
<li>Community health clinics with actual care time</li>
<li>Transportation systems designed for flow, not control</li>
<li>Apprenticeship programs instead of credential barriers</li>
</ul>
<p><strong>The tragic part:</strong> We already know these work. We have the examples. We're just afraid to try them at scale.</p>
<hr />
<h2>Part 5: The Breaking Point</h2>
<p><strong>Why this matters more now than ever</strong></p>
<h3>The Legitimacy Crisis</h3>
<ul>
<li>Institutions losing trust precisely because their design breaks trust</li>
<li>Can't rebuild trust with PR campaigns</li>
<li>Have to actually redesign systems</li>
<li>Current trajectory: more control → less trust → demands for change → more control</li>
<li>This ends badly</li>
</ul>
<h3>The AI Amplification Risk</h3>
<ul>
<li>Every control system we've built becomes supercharged with AI</li>
<li>Surveillance becomes perfect, inescapable</li>
<li>But the underlying problem (mistrust) gets exponentially worse</li>
<li>We're automating dystopia unless we change direction</li>
<li>Alternative: AI could enable trust-based systems to scale</li>
</ul>
<h3>The Generational Divide</h3>
<ul>
<li>Younger generations recognize the systems are broken</li>
<li>They're opting out: quiet quitting, FIRE movement, alternative lifestyles</li>
<li>The social contract is already broken</li>
<li>Choice: redesign from trust, or watch systems collapse from distrust</li>
</ul>
<h3>The Geopolitical Dimension</h3>
<ul>
<li>Authoritarian systems are doubling down on control</li>
<li>Democratic systems adding surveillance and restrictions</li>
<li>The irony: we're becoming what we claim to oppose</li>
<li>Competitive advantage goes to societies that unlock human potential</li>
<li>That requires trust-based design</li>
</ul>
<hr />
<h2>Part 6: The Way Out</h2>
<p><strong>How to stop building systems that make things worse</strong></p>
<h3>Start With One Question</h3>
<p>Before building any new system or fixing an old one, ask: <strong>"What are we assuming people will do wrong, and what if we're wrong about that?"</strong></p>
<h3>The Audit You Need</h3>
<p>Look at your three most expensive control systems:</p>
<ul>
<li>What problem were they supposed to solve?</li>
<li>Did they solve it?</li>
<li>What new problems did they create?</li>
<li>What would happen if you removed them?</li>
<li>What would you do with the money instead?</li>
</ul>
<h3>The Small Bets Strategy</h3>
<ul>
<li>You don't have to transform everything at once</li>
<li>Find one expensive control system</li>
<li>Run an experiment with trust-based alternative</li>
<li>Measure what actually matters (not what's easy to measure)</li>
<li>Learn, iterate, expand</li>
</ul>
<h3>The Pattern Recognition Skill</h3>
<ul>
<li>Train yourself to see mistrust-by-design</li>
<li>Every security gate, permission slip, surveillance camera</li>
<li>Ask: "Is this solving a real problem or performing security theater?"</li>
<li>Ask: "What would a trust-based alternative look like?"</li>
<li>Collect examples of trust-based systems that work</li>
</ul>
<h3>The Coalition Building</h3>
<ul>
<li>You can't do this alone</li>
<li>Find others who see the pattern</li>
<li>Share stories of successful trust-based alternatives</li>
<li>Build political will for redesign</li>
<li>Make the economic case: trust is cheaper</li>
</ul>
<hr />
<h2>Closing: The Choice</h2>
<p>We're at an inflection point. We can:</p>
<p><strong>Option A:</strong> Keep building billion-dollar systems that make problems worse</p>
<ul>
<li>More surveillance, more control, more alienation</li>
<li>Higher costs, lower trust, worse outcomes</li>
<li>Eventually, system collapse or authoritarianism</li>
</ul>
<p><strong>Option B:</strong> Start designing from trust</p>
<ul>
<li>Cheaper, more effective, more humane</li>
<li>Unlocks innovation, builds community, creates resilience</li>
<li>Requires courage to flip our assumptions</li>
</ul>
<p>The evidence is already in. Trust-based systems work. They're more efficient, more adaptive, more humane. We're just too scared to build them at scale.</p>
<p>But the cost of mistrust is becoming unbearable. And the systems we've built are starting to fail catastrophically.</p>
<p><strong>The question isn't whether we CAN design from trust. The question is whether we'll do it before the mistrust-based systems collapse entirely.</strong></p>
<hr />
<h2>Potential Case Studies to Research/Add:</h2>
<ul>
<li><strong>Valve Software</strong> (no managers, flat hierarchy) - gaming company</li>
<li><strong>Gore-Tex</strong> (lattice organization) - manufacturing</li>
<li><strong>Handelsbanken</strong> (no budgets, branch autonomy) - banking</li>
<li><strong>Finnish education system</strong> (high trust, low testing, excellent outcomes)</li>
<li><strong>Mondragon</strong> (worker cooperative, 80,000+ employees)</li>
<li><strong>Patagonia</strong> (trust-based retail, environmental mission)</li>
<li><strong>REI</strong> (cooperative model)</li>
</ul>
<h2>New Insights to Develop:</h2>
<ul>
<li><strong>The Control Paradox:</strong> The more you tighten control, the more it slips away</li>
<li><strong>The Accountability Illusion:</strong> Heavy documentation doesn't create accountability, it creates CYA behavior</li>
<li><strong>The Innovation Ceiling:</strong> Control systems cap innovation at "approved" level</li>
<li><strong>The Trust Dividend:</strong> Organizations that design from trust get exponential returns</li>
<li><strong>The Surveillance Spiral:</strong> Each layer of surveillance demands more surveillance to monitor the monitors</li>
</ul>
<hr />
<p>This outline gives you a structure as substantive as the DfT post, with a sharper critical edge. It names the villain (mistrust-by-design), shows the damage (with specific costs and examples), and offers the alternative (trust-based systems with proof they work).</p>
<p>The tone would be more urgent and critical than the DfT post—less "here's an interesting pattern" and more "we're actively breaking everything and here's how to stop."</p>

      
    </div>
  </div>
  <script src="/ogm-wiki/markpub_static/js/script.js"></script>
  
  <footer class="footer">
  <div class="content has-text-centered">
    
    <div><strong>OGM Wiki</strong> by the Open Global Mind community.</div>
    
    
    <div>Central repository at <a href="https://github.com/openglobalmind/ogm-wiki">GitHub/openglobalmind/ogm-wiki</a>.</div>
    
    
    <div>Licensed under <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</div>
    
    <div><em>Site last updated on Wednesday, January 28, 2026 at 16:58 UTC.</em></div>
  </div>
</footer>
</body>
</html>